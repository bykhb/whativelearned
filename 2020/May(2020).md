- Cloud

  (1). rest api<br>
  (2). 
  
------------------------------------------------------
- Model
  (1). gradient descent > Analytic solution : more scalable, and more suitable for large number of features.
  GD doesn't require to invert a matrix
  
------------------------------------------------------
- Model Pipeline

  (1). label 관리 <br>
  
  (2). Data Flow
  
------------------------------------------------------
- Model Metrics

  (1).
  
------------------------------------------------------
- Model Interpretation

  (1). Feature Importance <br>
  
  (2). PDF <br>
  
  (3). LIME <br>
  
  (4). Shape <br>
  
------------------------------------------------------  
- Customer Profiling 

  (1). medium <br>

------------------------------------------------------
- DB

  (1). Partitioned Table vs Wildcard Table <br>
  
  (2). 정규화 <br>
  
  (3). SQL 샘플 사이트 검색 <br>
  
------------------------------------------------------
- Data Analytics

  (1). "만약 당신의 사진이 만족스럽지 않다면, 그것은 충분히 가까이 가지 않았기 때문입니다." —> "만약 당신의 분석이 만족스럽지 않다면, 그것은 충분히 나누지 않았기 때문입니다." <br>
  
  (2). "데이터를 이해할 수 있을만큼 충분히 똑똑하고, 그것을 무시할만큼의 직관을 갖춘" by 패티 맥코드(넷플릭스)
  
  (3). 비즈니스 가치를 증명하기 위해 업무의 복잡성을 보여줄 필요는 없다. 무엇을 했는지, 어떻게 했는지를 이야기 하지 말고,
  의사 결정을 어떻게 지원할 것인지에 관해 가장 많은 시간을 투자해야 한다. 업무 일기를 궁금해하는 사람은 아무도 없다. 어떤 결과를 만들었고, 이 결과물의 가치가 어떤지에 대해 말하면 된다.
  
  때떄로 유사성을 활용하는 것이 도움이 된다.
  
  (4). 
  
  
  
------------------------------------------------------
- Recommendation

  (1). 상품의 개수에서 오는 차이가 개인화를 가로막는 것 아닌가 싶네...
  개인화가 가능하여 효과가 큰 영역과 그렇지 않은 영역간의 차이가.
  추천할 수 있는 제품의 개수가 적은 회사는 추천과 궁합이 좋지 않은 것 같다.
 
------------------------------------------------------  
- ETC

  (1). KNIME github <br>
  
  (2). Deep code <br>
  
  (3). pickle 형식이란?? <br>
  
  (4). 제로샷, transfer learningd <br>
  
  (5). API 개발이란?? <br>
  
  (6). What is KIBANA? <br>
  
  (7). What is '엔터프라이즈급 애플리케이션???' <br>
  
  (8). 
  
------------------------------------------------------
- Search

  (1). Label 추가 + Model 학습 갱신(continuous learning) <br>
  
    > To get an intuitive understanding of why this happens, first consider a classic ML task: Classifying cat images. The visual properties of cats are stable over time (unless we start looking at evolutionary time scales), so when we train a neural network to recognize pictures of cats, an implicit assumption is that the features that define cats are going to remain the same for the foreseeable future. We don’t expect cats to look different next week, or next year, or even ten years from now. Given enough data, the model we trained this week is good enough for the foreseeable future as well.
    In statistical parlance, we say that the distribution of cat picture features is a stationary distribution, meaning that its properties such as its mean and standard deviation remain the same over time.
    
    > The only way around this is to retrain your model every time you get new data. Note that this is not the same as continuous learning, where an already trained model is updated as new data comes in. You are actually retraining a new model from scratch everytime you want to generate a new forecast (although it would be an interesting research topic to see if continuous learning can be applied to time series forecasting).


  (2). REST API <br>
  
  (3). autocorrelation, cross-correlation <br>
  
  (4). gibbs sampling <br>
  
  (5). error analysis <br>
  
  (6). ML 파이프라인 -> kubeflow <br>
  
  (7). Restful API <br>
  
  (8). GCS, SPARK(Py) <br>
  
  (9). QA, 운영 환경 <br>
  
  
  


