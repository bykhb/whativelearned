- AI가 태동하던 시절, 컴퓨터 과학자들은 컴퓨터에 사람의 정신을 일부나마 재현하려 시도했다. 
공상과학 소설이나 영화에 나오는 지능을 구현하려 시도한 것이다. 즉, 인간처럼 생각하는 기계를 말하는 것이다. 
이런 종류의 지능(인텔리전스)을 ‘인텔리저빌리티(Intelligibility)’로 부른다. 

한편 인텔리저빌리티를 갖춘 컴퓨터를 사용하면, 역으로 인간의 추론, 학습, 인식, 기타 정신적 행동 방식을 탐구할 수도 있을 것으로 기대됐다.
초기 인텔리저빌리티 연구들은 실제 세상과 (인지 과학의 영역인) 정신의 일부를 컴퓨터에 모델링하는 것에 초점을 맞췄다. 
무려 60년 전에 이런 실험을 했다는 사실이 무척 놀랍다.

초기 인텔리전스 모델들은 연역적 추론(deductive reasoning)에 초점을 맞췄다. 가장 잘 알려진 이런 종류의 초기 AI 프로그램 중 하나는 
인간의 문제 해결 능력을 흉내내기 위해 1956년 만든 ‘논리 이론가(Logic Theorist)’이다. 
‘논리 이론가’는 수학 이론(Principia Mathematica) 2장의 첫 52개 정리(Theorem) 가운데 38개를 증명했으며, 한 가지 정리를 발전시켰다. 
‘논리 이론가’는 머신이 (당시 기준으로) 지능과 창조력이 요구되는 것으로 간주되었던 작업을 처리할 수 있다는 점을 사상 처음 증명해 보였다.
곧이어 과학자들은 다른 종류의 사고, 귀납적 추론(inductive reasoning)을 연구하기 시작했다. 데이터를 조사, 이를 설명할 가설을 도출하려 
시도할 때 귀납적 추론이 사용되곤 한다. 과학자들은 귀납적 추론을 연구하기 위해 NASA 연구소 과학자들의 유기 화학에 대한 지식을 이용, 
이들이 유기 분자를 파악하도록 도움을 주는 인지 모델을 만들었다. 이 덴드랄(Dendral) 프로그램은 인공지능의 두 번째 특징적 기능인 
인스트루멘탈리티(Instrumentality)를 처음으로 실례로 보여줬다. 인스트루멘탈리티는 (이 경우에는 분자 파악인) 귀납적 추론 작업을 
수행할 수 있는 기법이나 알고리즘이다.

덴드랄은 초기 지식 기반(the first knowledge base)을 포함하고 있다는 점에서 독특했다. 초기 지식 기반이란 과학자들이 인지 모델과 
함께 사용하기 위한 목적에서 지식을 캡처한 이프/덴 규칙 세트를 말한다. 이후 이런 형태의 지식을 ‘전문가 시스템’(expert system)이라고 부르게 됐다.
단일 프로그램에서 이 두 종류의 지능을 모두 사용할 수 있도록 함으로써 ‘특정 과학자를 다른 과학자보다 더 낫게 만드는 것은 무엇일까? 
인지 능력이 더 뛰어나서일까? 아니면 지식이 더 많아서일까?’라는 질문을 물을 수 있었다.
1960년대 말에 이런 질문에 대한 답이 명확해졌다. 전문가들로부터 획득한 지식의 양과 질이 댄드랄의 성능을 결정했었다. 
인지 모델은 댄드랄의 성능과 일부 관련을 가질 뿐이었다.이를 깨닫게 된 것이 AI 공동체에 패러다임 변화를 가져왔다. 
‘지식’이 전문가 시스템을 사용해 인간의 특정 전문 분야를 모델화하는 방법적 원칙으로 부상했다. 
이렇게 만든 전문가 시스템은 인간 의사 결정자 한 명의 능력을 능가하는 경우가 많았다. 
이런 놀라운 성공이 정보(첩보) 분야, 군, 산업, 투자자, 대중지 분야에서 전문가 시스템에 대한 큰 관심을 촉발했다.
전문가 시스템이 상업적으로 성공을 거두면서, 연구원들은 이런 시스템을 모델링하고 여러 문제 영역에서 더 유연하게 활용할 수 있도록 
만드는 기법들로 시선을 돌렸다. 이 기간, AI 분야는 객체 지향형 디자인과 계층 온톨로지(Hierarchical ontologies)를 개발했고,
다른 컴퓨터 관련 공동체에서 이를 도입했다. 현재 이 계층 온톨리지는 최근 몇 년 동안 다시 부상을 하면서 지식 그래프의 중심이 되었다.

이 때 연구원들은 ‘1차 술어 논리(First order predicate logic)’라는 지식 개념에 초점을 맞추었고, 이를 통해 자동으로 학습할 수 있는 
시스템을 발견했다. 이는 스스로 추가 데이터를 토대로 성능을 향상시키는 규칙을 생성 및 재생성 할 수 있는 시스템이다. 
덴드랄을 수정, 실험에서 얻은 경험적 데이터를 토대로 질량 분석 규칙을 학습할 수 있는 기능을 부여했다.
이런 전문가 시스템은 훌륭했지만 한계도 존재했다. 통상 특정 문제 영역에만 국한되는 문제가 있었고, 다른 여러 가능한 대안들을 구별하지 못했다.
또 구조나 통계적 상관관계에 대한 지식을 사용하지 못했다. 연구원들은 이런 문제들 가운데 일부를 극복하기 위해, 특정 팩트가 ‘참’일 확률을 
알려주는 수치(값)인 시-에프(Certainty factor, 확신도)를 추가했다.
연구원들이 시-에프를 통계 모델로 구현할 수 있다는 사실을 발견하면서 두 번째 패러다임 변화가 발생했다. 
통계와 베이즈 추론(Bayesian inference)을 사용, 경험적 데이터에서 도메인(특정 영역) 전문성을 모델링할 수 있었다. 
이 시점부터 AI에서 머신러닝(ML)의 비중이 커지기 시작했다.
그러나 문제점이 있었다. 랜덤 포레스트와 뉴럴 네트워크, GBT(Gradient Boosted Trees) 같은 ML기법들은 정확한 결과를 생성하지만, 
불가해한 블랙박스를 닮은 특성을 보인다. ‘인텔리저블’ 아웃풋이 없다면, ML모델은 몇몇 측면에서 기존 모델보다 유용하지 못하다. 
예를 들어, 전통적인 AI 모델의 경우 관련 분야 종사자들이 다음과 같은 질문을 물을 수 있다.

- 모델이 실수를 한 이유는 무엇이었을까?
- 모델이 편향되어 있는가?
- 규제 컴플라이언스를 증명할 수 있는가?
- 모델이 도메인 전문가의 의견과 불일치하는 이유는 무엇인가?

이렇게 해석가능성이 미흡한 문제는 트레이닝에도 영향을 줬다. 모델에 문제가 있지만 이유를 설명할 수 없을 때 수정이 훨씬 더 어려워진다. 
더 많은 표본(예)을 추가할까? 어떤 표본(예)?
잠정적으로 단순하게 절충할 수 있기는 하다. 덜 정확한 예측을 받아들이는 것을 예로 들 수 있다. 
그렇지만 ML모델을 설명하는 능력이 AI와 관련해 앞으로 달성해야 할 중요한 중간 목표 중 하나로 부상했다.
역사는 반복된다. 초기 AI 연구는 오늘날처럼 사람의 추론 능력 인지 모델 모델링에 초점을 맞췄었다. 초기 AI 연구원들이 직면했던 
3가지 문제(지식, 설명, 유연성)는 지금도 머신러닝 시스템에 대한 담론의 중심으로 남아있다.
지식은 이제 데이터의 형태를 갖고 있으며, 뉴럴 네트워크의 취약성으로 인해 유연성(적응성)이 요구되고 있다. 
데이터에 조금 문제가 있을 때 아주 다른 결과가 생성될 수 있기 때문이다. 
설명 가능성(Explainability) 또한 우선순위 중 하나로 부상했다. 이제 기계가 어떻게 생각하는지 물어야 하는 것이다. 
인간의 생각 방식을 복제하려 했던 60년 전을 떠올리면 꽤나 아이러니한 변화다. 

-----

